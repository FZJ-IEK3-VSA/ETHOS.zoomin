import os
import time 
import traceback
import json
from zoomin import disaggregation_manager as disagg_manager
from zoomin import snakemake_utils as sm_utls
from zoomin.post_disagg_calculation import perform_post_disagg_calculation
from dotenv import load_dotenv, find_dotenv

# find .env automagically by walking up directories until it's found
dotenv_path = find_dotenv()
# load up the entries as environment variables
load_dotenv(dotenv_path)

db_name = os.environ.get("DB_NAME")

bad_proxy_dict = {}

mini_db = int(os.environ.get("MINI_DB"))

def log_error(error, file_name):
    FILE_PATH = f"output_logs/{db_name}/error_{file_name}.log"

    with open(FILE_PATH, 'w') as f:
        print(error)
        f.write(error)

rule all:
    input:
        "bad_proxy_log.json"

collected_vars_lau = sm_utls.get_collected_vars("LAU")
collected_vars_nuts3 = sm_utls.get_collected_vars("NUTS3") 
collected_vars_nuts2 = sm_utls.get_collected_vars("NUTS2")
collected_vars_nuts0 = sm_utls.get_collected_vars("NUTS0") 
collected_vars_post_disagg_calc = sm_utls.get_collected_vars("with_post_disagg_calc")

# Define a wildcard for each parameter
wildcard_constraints:
    # collected vars
    wc_collected_var_lau = "|".join(collected_vars_lau),
    wc_collected_var_nuts3 = "|".join(collected_vars_nuts3), 
    wc_collected_var_nuts2 = "|".join(collected_vars_nuts2), 
    wc_collected_var_nuts0 = "|".join(collected_vars_nuts0), 
    wc_collected_var_post_disagg_calc = "|".join(collected_vars_post_disagg_calc),
    wc_db_name = db_name

# ========================================================
#############      COLLECTED VARS     ####################
# ========================================================

# LAU data
rule disaggregate_collected_vars_lau:
    output:
        touch("output_logs/{wc_db_name}/{wc_collected_var_lau}.log")
    run:
        try:
            bad_proxy = disagg_manager.process_collected_var(wildcards.wc_collected_var_lau)

            if bad_proxy is not None:
                bad_proxy_dict.update({wildcards.wc_collected_var_lau: bad_proxy})

        except Exception as e:
            log_error(traceback.format_exc(), wildcards.wc_collected_var_lau)
            raise e

rule end_of_lau:
    input:
        expand("output_logs/{db_name}/{var_name}.log", 
        db_name=db_name,
        var_name=collected_vars_lau)
    output:
        touch("output_logs/{wc_db_name}/finished_lau.log")


# NUTS3
rule save_predictor_df_for_nuts3:
    input:
        f"output_logs/{db_name}/finished_lau.log" #if mini_db == 1 else None
    output:
        f"../../data/predictor_df_for_NUTS3_{db_name}.csv"
    run:
        sm_utls.save_predictor_df("NUTS3")


rule disaggregate_collected_vars_nuts3:
    input:
        f"../../data/predictor_df_for_NUTS3_{db_name}.csv",
        f"output_logs/{db_name}/finished_lau.log"
    output:
        touch("output_logs/{wc_db_name}/{wc_collected_var_nuts3}.log")
    params:
        delay=10  # seconds
    run:
        try:
            bad_proxy = disagg_manager.process_collected_var(wildcards.wc_collected_var_nuts3)

            if bad_proxy is not None:
                bad_proxy_dict.update({wildcards.wc_collected_var_nuts3: bad_proxy})

        except Exception as e:
            log_error(traceback.format_exc(), wildcards.wc_collected_var_nuts3)
            raise e

rule end_of_nuts3:
    input:
        expand("output_logs/{db_name}/{var_name}.log", 
        db_name=db_name,
        var_name=collected_vars_nuts3)
    output:
        touch("output_logs/{wc_db_name}/finished_nuts3.log")

# NUTS2
rule save_predictor_df_for_nuts2:
    input:
        f"output_logs/{db_name}/finished_nuts3.log" #if mini_db == 1 else None
    output:
        f"../../data/predictor_df_for_NUTS2_{db_name}.csv"
    run:
        sm_utls.save_predictor_df("NUTS2")


rule disaggregate_collected_vars_nuts2:
    input:
        f"../../data/predictor_df_for_NUTS2_{db_name}.csv",
        f"output_logs/{db_name}/finished_nuts3.log"
    output:
        touch("output_logs/{wc_db_name}/{wc_collected_var_nuts2}.log")
    params:
        delay=10  # seconds
    run:
        try:
            bad_proxy = disagg_manager.process_collected_var(wildcards.wc_collected_var_nuts2)

            if bad_proxy is not None:
                bad_proxy_dict.update({wildcards.wc_collected_var_nuts2})

        except Exception as e:
            log_error(traceback.format_exc(), wildcards.wc_collected_var_nuts2)
            raise e


rule end_of_nuts2:
    input:
        expand("output_logs/{db_name}/{var_name}.log", 
        db_name=db_name,
        var_name=collected_vars_nuts2)
    output:
        touch("output_logs/{wc_db_name}/finished_nuts2.log")

# NUTS0
rule disaggregate_collected_vars_nuts0:
    input:
        f"output_logs/{db_name}/finished_nuts2.log"
    output:
        touch("output_logs/{wc_db_name}/{wc_collected_var_nuts0}.log")
    run:
        try:
            bad_proxy = disagg_manager.process_collected_var(wildcards.wc_collected_var_nuts0)

            if bad_proxy is not None:
                bad_proxy_dict.update({wildcards.wc_collected_var_nuts0: bad_proxy})

        except Exception as e:
            log_error(traceback.format_exc(), wildcards.wc_collected_var_nuts0)
            raise e

rule end_of_nuts0:
    input:
        expand("output_logs/{db_name}/{var_name}.log", 
        db_name=db_name,
        var_name=collected_vars_nuts0)
    output:
        touch("output_logs/{wc_db_name}/finished_nuts0.log")


# POST DISAGGREGATION CALCULATION 

rule calculate_collected_vars_post_disaggregation:
    input:
        f"output_logs/{db_name}/finished_nuts0.log"
    output:
        touch("output_logs/{wc_db_name}/{wc_collected_var_post_disagg_calc}.log")
    run:
        try:
            perform_post_disagg_calculation(wildcards.wc_collected_var_post_disagg_calc)

        except Exception as e:
            log_error(traceback.format_exc(), wildcards.wc_collected_var_post_disagg_calc)
            raise e

#================================================================================================

rule final:
    input:
        expand("output_logs/{db_name}/{var_name}.log", 
                db_name=db_name,
                var_name=collected_vars_post_disagg_calc)
    output:
        "bad_proxy_log.json"
    run:
        # log bad proxies 
        with open("bad_proxy_log.json", 'w') as fp:
            json.dump(bad_proxy_dict, fp)
