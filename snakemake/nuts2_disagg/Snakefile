import os
import time 
import traceback
import json
from zoomin import disaggregation_manager as disagg_manager
from zoomin import snakemake_utils as sm_utls
from dotenv import load_dotenv, find_dotenv

# find .env automagically by walking up directories until it's found
dotenv_path = find_dotenv()
# load up the entries as environment variables
load_dotenv(dotenv_path)

db_name = os.environ.get("DB_NAME")

bad_proxy_dict = {}

mini_db = int(os.environ.get("MINI_DB"))

collected_vars_nuts0 = sm_utls.get_collected_vars("NUTS0") #NOTE: there are no vars collected at NUTS1 level

if mini_db == 1:
    eucalc_years = ["2020", "2030"]
else:
    eucalc_years = ["2020", "2025", "2030", "2035", "2040", "2045", "2050"]

pathways = ["national", "with_behavioural_changes"]
eucalc_vars = sm_utls.get_eucalc_vars()

def log_error(error, file_name):
    FILE_PATH = f"output_logs/{db_name}/error_{file_name}.log"

    with open(FILE_PATH, 'w') as f:
        print(error)
        f.write(error)

rule all:
    input:
        f"output_logs/bad_proxy_{db_name}.json"


# Define a wildcard for each parameter
wildcard_constraints:
    wc_collected_var_nuts0 = "|".join(collected_vars_nuts0), 
    wc_pathway = "|".join(pathways),
    wc_eucalc_var = "|".join(eucalc_vars),
    wc_eucalc_year = "|".join(eucalc_years),
    wc_db_name = db_name

# DISAGGREGATE COLLECTED NUTS0 VARS --------------------------------
rule disaggregate_nuts0_collected_vars:
    output:
        touch("output_logs/{wc_db_name}/collected_vars/{wc_collected_var_nuts0}.log")
    run:
        try:
            bad_proxy = disagg_manager.disaggregate_collected_var(wildcards.wc_collected_var_nuts0,
                                                                source_resolution = "NUTS0",
                                                                target_resolution = "NUTS2")

            if bad_proxy is not None:
                bad_proxy_dict.update({wildcards.wc_collected_var_nuts0: bad_proxy})

        except Exception as e:
            sm_utls.clear_rows_from_processed_data(wildcards.wc_collected_var_nuts0, 
                                                    target_resolution='NUTS2')
            log_error(traceback.format_exc(), wildcards.wc_collected_var_nuts0)
            raise e

rule end_of_nuts0_collected_vars:
    input:
        expand("output_logs/{db_name}/collected_vars/{var_name}.log", 
        db_name=db_name,
        var_name=collected_vars_nuts0)
    output:
        touch("output_logs/{wc_db_name}/finished_collected_vars_nuts0.log")

# DISAGGREGATE EUCALC VARS --------------------------------
rule disaggregate_eucalc_vars:
    output:
        touch("output_logs/{wc_db_name}/eucalc_vars/{wc_eucalc_var}_{wc_eucalc_year}_{wc_pathway}.log")
    run:
        try:
            bad_proxy = disagg_manager.disaggregate_eucalc_var(wildcards.wc_eucalc_var, 
                                                wildcards.wc_pathway,
                                                wildcards.wc_eucalc_year,
                                                "NUTS2")

            if bad_proxy is not None:
                bad_proxy_dict.update({f"{wildcards.wc_eucalc_var}_{wildcards.wc_eucalc_year}_{wildcards.wc_pathway}": bad_proxy})

        except Exception as e:
            sm_utls.clear_rows_from_processed_data(wildcards.wc_eucalc_var, 
                                                "NUTS2", 
                                                wildcards.wc_eucalc_year, 
                                                wildcards.wc_pathway)
            log_error(traceback.format_exc(), f"{wildcards.wc_eucalc_var}_{wildcards.wc_eucalc_year}_{wildcards.wc_pathway}")
            raise e
            
rule end_of_eucalc_vars:
    input:
        expand("output_logs/{db_name}/eucalc_vars/{var_name}_{year}_{pathway}.log", 
                db_name=db_name,
                var_name=eucalc_vars,
                year=eucalc_years,
                pathway=pathways)
    output:
        touch("output_logs/{wc_db_name}/finished_eucalc_vars.log")

# FINAL  --------------------------------
rule final:
    input:
        f"output_logs/{db_name}/finished_collected_vars_nuts0.log",
        f"output_logs/{db_name}/finished_eucalc_vars.log"
    output:
        f"output_logs/bad_proxy_{db_name}.json"
    run:
        # log bad proxies 
        with open(f"output_logs/bad_proxy_{db_name}.json", 'w') as fp:
            json.dump(bad_proxy_dict, fp)
